{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pdfkit\n",
    "import urllib.parse\n",
    "import os\n",
    "import concurrent.futures\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_wkhtmltopdf = r'C:\\Program Files\\wkhtmltopdf\\bin\\wkhtmltopdf.exe'  # Thay đổi theo đường dẫn của bạn\n",
    "config = pdfkit.configuration(wkhtmltopdf=path_wkhtmltopdf)\n",
    "options = {\n",
    "    'no-stop-slow-scripts': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NmJ5WHc3WSt4VVI2V0VEQ2UySlBPdz09', 'Nk9SMW9aZUlRYk05VElGWnVVeVBaQT09', 'TVRHVGZob1M3Rkluc1NtaDFucm1ndz09', 'MFhDdjFCV0N5SUZMd21QNmttbDlvZz09', 'aCtzQVM4eUtqNjVndWd1UElMaHhWdz09', 'cU01NHA5Sk5UN1g0RWFVQWcxV2hGUT09']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cids_fail_round2.csv')\n",
    "\n",
    "# Chuyển đổi cột đầu tiên thành danh sách\n",
    "cids_list = df.iloc[:, 0].tolist()  # Lấy cột đầu tiên\n",
    "\n",
    "# In ra danh sách\n",
    "print(cids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NmJ5WHc3WSt4VVI2V0VEQ2UySlBPdz09'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cids_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_cv(cid, download_folder):\n",
    "    base_url = \"https://employer.jobsgo.vn/candidate/detail\"\n",
    "    params = {\n",
    "        \"cid\": cid\n",
    "    }\n",
    "    cid_id = cid[-5:]\n",
    "    # Headers\n",
    "    headers = {\n",
    "        \"Accept\": \"*/*\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9,vi;q=0.8,vi-VN;q=0.7\",\n",
    "        \"Cache-Control\": \"no-cache\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Cookie\": \"colorgb-employer=ars0g0ndqor5g1ibudmnbed0gb; _identity-colorgb-employer=b09b08c1d2b4e46c3f112b5cd5f9b660b4ef707832b3c7061f29eac2cdd0c08ba%3A2%3A%7Bi%3A0%3Bs%3A26%3A%22_identity-colorgb-employer%22%3Bi%3A1%3Bs%3A22%3A%22%5B256330984%2C%22%22%2C2592000%5D%22%3B%7D; _csrf-colorgb-employer=6e54d3978a91607f4bb1a6ca36b2ac47cacd35461e09efc0a770d42cff03b1d9a%3A2%3A%7Bi%3A0%3Bs%3A22%3A%22_csrf-colorgb-employer%22%3Bi%3A1%3Bs%3A32%3A%22plo_dhvcuuM3upxK7yrhLN4mcpXkrcwh%22%3B%7D; last_logout=593d7738957e8373e82bcb944e31a3e0ab199588d6a42b5ca71a5616096b9a45a%3A2%3A%7Bi%3A0%3Bs%3A11%3A%22last_logout%22%3Bi%3A1%3Bi%3A1728444905%3B%7D; jobsgo-subemployer-logged-161233-256330984=1; alert-info=21d557c682fc76d6dfb3940f0540fd0ce90331f46673c55dc69792c561dbe1e5a%3A2%3A%7Bi%3A0%3Bs%3A10%3A%22alert-info%22%3Bi%3A1%3Bi%3A5%3B%7D\",\n",
    "        \"DNT\": \"1\",\n",
    "        \"Pragma\": \"no-cache\",\n",
    "        \"Referer\": \"https://employer.jobsgo.vn/job/detail/19037635789?tab=suggest\",\n",
    "        \"Sec-Fetch-Dest\": \"empty\",\n",
    "        \"Sec-Fetch-Mode\": \"cors\",\n",
    "        \"Sec-Fetch-Site\": \"same-origin\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"sec-ch-ua\": \"\\\"Google Chrome\\\";v=\\\"129\\\", \\\"Not=A?Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"129\\\"\",\n",
    "        \"sec-ch-ua-mobile\": \"?0\",\n",
    "        \"sec-ch-ua-platform\": \"\\\"Windows\\\"\"\n",
    "    }\n",
    "    print(f\"{base_url}?cid={cid}\")\n",
    "    response = requests.get(base_url, params=params, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Loại bỏ tất cả các thẻ <script>\n",
    "    for script in soup.find_all('script'):\n",
    "        script.decompose()\n",
    "\n",
    "    # Loại bỏ tất cả các thẻ <div class=\"modal\">\n",
    "    for modal in soup.find_all('div', class_='modal'):\n",
    "        modal.decompose()\n",
    "\n",
    "    # Lưu thẻ <section class=\"portfolio\" vào biến trước khi xóa\n",
    "    portfolio_session = soup.find('section', class_='portfolio')\n",
    "\n",
    "    # Kiểm tra xem thẻ có tồn tại không trước khi xóa\n",
    "    if portfolio_session:\n",
    "        # Lưu lại nội dung của portfolio_session nếu cần\n",
    "        portfolio_session_copy = str(portfolio_session)\n",
    "        portfolio_session_copy = BeautifulSoup(portfolio_session_copy)\n",
    "        # Xóa thẻ trong soup\n",
    "        portfolio_session.decompose()\n",
    "    else:\n",
    "        True\n",
    "        portfolio_session_copy = BeautifulSoup(\"\")\n",
    "\n",
    "    name = soup.find('div', class_='profile').find('h1').get_text()\n",
    "\n",
    "    filename_html_pdf = f\"{name}_{cid_id}_html.pdf\"\n",
    "    html_content = str(soup)\n",
    "    # Lưu pdf\n",
    "    pdf_file_path = os.path.join(download_folder, 'test1.pdf')\n",
    "    try:\n",
    "        pdfkit.from_string(html_content, pdf_file_path, configuration=config, options=options)\n",
    "        print(\"PDF đã được tạo thành công.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Không thể tạo PDF, lỗi: {e}\")\n",
    "\n",
    "    try:\n",
    "        os.rename(pdf_file_path, os.path.join(download_folder, filename_html_pdf))\n",
    "        print(f\"File đã được đổi tên thành: {filename_html_pdf}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Không thể đổi tên file, lỗi: {e}\")\n",
    "\n",
    "    if portfolio_session_copy:\n",
    "        # Tìm tất cả các iframe trong section\n",
    "        links = portfolio_session_copy.find_all('iframe')\n",
    "        \n",
    "        # In ra danh sách các đường link và ngày cập nhật\n",
    "        print(\"Danh sách các đường link và ngày cập nhật:\")\n",
    "        for i, link in enumerate(links):\n",
    "            original_url = link.get('src')\n",
    "\n",
    "            # Tách phần query từ URL\n",
    "            parsed_url = urllib.parse.urlparse(original_url)\n",
    "            query_params = urllib.parse.parse_qs(parsed_url.query)\n",
    "\n",
    "            # Lấy giá trị của tham số 'file' và giải mã\n",
    "            if 'file' in query_params:\n",
    "                encoded_file_url = query_params['file'][0]\n",
    "                decoded_file_url = urllib.parse.unquote(encoded_file_url)\n",
    "\n",
    "                # In ra đường link đã được giải mã\n",
    "                print(\"Đường link mới:\", decoded_file_url)\n",
    "\n",
    "                # Tìm tất cả các thẻ <p> trước thẻ iframe\n",
    "                previous_paragraphs = link.find_all_previous('p')\n",
    "\n",
    "                # Lọc các thẻ <p> chứa \"Cập nhật ngày\"\n",
    "                update_paragraphs = [p for p in previous_paragraphs if 'Cập nhật ngày' in p.get_text()]\n",
    "\n",
    "                # Lấy thẻ <p> đầu tiên (lớn nhất) nếu tồn tại\n",
    "                if update_paragraphs:\n",
    "                    latest_update_paragraph = update_paragraphs[0]  # Thẻ <p> đầu tiên trong danh sách\n",
    "                    update_date = latest_update_paragraph.get_text().split(': ')[1]  # Lấy phần sau dấu ':'\n",
    "                    update_date = update_date.replace(\"/\",\"-\")\n",
    "                    print(f\"Ngày cập nhật: {update_date}\")\n",
    "                else:\n",
    "                    print(\"Không tìm thấy ngày cập nhật.\")\n",
    "\n",
    "\n",
    "            # URL của file PDF\n",
    "            url = decoded_file_url\n",
    "\n",
    "            # Gửi yêu cầu GET để tải file\n",
    "            response = requests.get(url)\n",
    "\n",
    "            # Kiểm tra xem yêu cầu có thành công không\n",
    "            if response.status_code == 200:\n",
    "                # Tên file để lưu\n",
    "                \n",
    "                filename = f\"{name}_{update_date}_{cid_id}_download_{i+1}.pdf\"\n",
    "                pdf_file_download_path = os.path.join(download_folder, filename)\n",
    "                # Ghi nội dung của response vào file\n",
    "                with open(pdf_file_download_path, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                \n",
    "                print(f\"File đã được tải xuống và lưu thành {pdf_file_download_path}.\")\n",
    "            else:\n",
    "                print(f\"Không thể tải file, mã lỗi: {response.status_code}\")\n",
    "    else:\n",
    "        True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_list(data, chunk_size):\n",
    "    \"\"\"Chia danh sách thành các phần nhỏ.\"\"\"\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i:i + chunk_size]\n",
    "\n",
    "\n",
    "def read_chunk_index(chunk_index):\n",
    "    \"\"\"Đọc chỉ số hiện tại của chunk từ file.\"\"\"\n",
    "    index_file = f'chunk_index_{chunk_index}.txt'\n",
    "    if os.path.exists(index_file):\n",
    "        with open(index_file, 'r') as f:\n",
    "            return int(f.read().strip())\n",
    "    return 0  # Nếu không có file, bắt đầu từ 0\n",
    "\n",
    "def write_chunk_index(chunk_index, current_index):\n",
    "    \"\"\"Ghi chỉ số hiện tại của chunk ra file.\"\"\"\n",
    "    index_file = f'chunk_index_{chunk_index}.txt'\n",
    "    with open(index_file, 'w') as f:\n",
    "        f.write(str(current_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_chunk(chunk, folder, index):\n",
    "    \"\"\"Xử lý từng chunk, theo dõi thời gian và lưu cid không thành công.\"\"\"\n",
    "    global failed_cids\n",
    "    current_index = read_chunk_index(index)  # Đọc chỉ số hiện tại từ file\n",
    "    \n",
    "    # Chạy từ chỉ số hiện tại đến hết chunk\n",
    "    for i, cid in enumerate(chunk[current_index:], start=current_index):\n",
    "        start_time = time.time()  # Ghi lại thời gian bắt đầu\n",
    "        print(f\"Đang tải CV {cid} trong chunk {index + 1} tại index {i}...\")\n",
    "\n",
    "        try:\n",
    "            download_cv(cid, folder)  # Gọi hàm tải CV\n",
    "            elapsed_time = time.time() - start_time  # Tính thời gian đã chạy\n",
    "\n",
    "            # Kiểm tra xem có quá thời gian không\n",
    "            if elapsed_time > 10:\n",
    "                print(f\"Thời gian quá lâu cho CV {cid}, sẽ lưu lại để thử lại sau.\")\n",
    "                failed_cids.append(cid)  # Lưu lại cid không thành công\n",
    "                break  # Thoát khỏi vòng lặp để xử lý các chunk khác\n",
    "            else:\n",
    "                write_chunk_index(index, i + 1)  # Ghi chỉ số hiện tại vào file\n",
    "        except Exception as e:\n",
    "            print(f\"Đã xảy ra lỗi khi tải CV {cid}: {e}\")\n",
    "            failed_cids.append(cid)  # Lưu lại cid không thành công\n",
    "            break  # Thoát khỏi vòng lặp để xử lý các chunk khác\n",
    "\n",
    "    # Nếu có cid không thành công, in ra danh sách\n",
    "    if failed_cids:\n",
    "        print(f\"Các CV không tải được trong chunk {index + 1}: {failed_cids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(failed_cids, columns=['cid'])\n",
    "\n",
    "# # Ghi DataFrame vào file CSV\n",
    "# df.to_csv('cids_fail_round2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Số lượng luồng\n",
    "num_threads = 10\n",
    "\n",
    "# Chia danh sách cids_list thành các phần\n",
    "cids_chunks = list(chunk_list(cids_list, len(cids_list) // num_threads + 1))\n",
    "\n",
    "# Danh sách để lưu lại các cid không thành công\n",
    "failed_cids = []\n",
    "\n",
    "# Sử dụng ThreadPoolExecutor để thực hiện multithreading\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "    futures = []\n",
    "    \n",
    "    # Gửi các nhiệm vụ tải CV cho từng phần\n",
    "    for index, chunk in enumerate(cids_chunks):\n",
    "        download_folder = f'cv_downloaded/chunk_{index+1}'  # Tạo tên thư mục cho chunk\n",
    "        os.makedirs(download_folder, exist_ok=True)  # Tạo thư mục nếu chưa tồn tại\n",
    "        \n",
    "        # Tạo một nhiệm vụ cho từng chunk\n",
    "        futures.append(executor.submit(handle_chunk, chunk, download_folder, index))\n",
    "\n",
    "    # Chờ tất cả các nhiệm vụ hoàn thành\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        try:\n",
    "            future.result()  # Nếu có lỗi, nó sẽ ném ra ngoại lệ\n",
    "        except Exception as e:\n",
    "            print(f\"Đã xảy ra lỗi: {e}\")\n",
    "\n",
    "print(\"Tất cả các CV đã được tải.\")\n",
    "\n",
    "\n",
    "# Sau đó bạn có thể thêm logic để thử lại các failed_cids nếu cần.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
